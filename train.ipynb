{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run LMLFM.ipynb\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats as st\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate simulated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run GeneratingSyntheticData.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total ratings to generate: 1600\n"
     ]
    }
   ],
   "source": [
    "n,m,p = 40,40,5000\n",
    "correlationType = \"both\"\n",
    "seed = 1\n",
    "\n",
    "np.random.seed(seed)  # this is fixed\n",
    "non_zero = 10 # only keep 10 non-zero effects\n",
    "bi = np.random.uniform(1,0,size=non_zero)\n",
    "bo = np.random.uniform(1,0,size=non_zero)\n",
    "bi = np.append(bi,np.zeros(p - non_zero))\n",
    "if p < 15:\n",
    "    bo = np.concatenate([np.zeros(5),bo])[:p]\n",
    "else:\n",
    "    bo = np.concatenate([np.zeros(5),bo,np.zeros(p - 15)])\n",
    "fixedEff = [1,2,3,-1,-2,-3,7,10]\n",
    "fixedEff = np.concatenate([fixedEff,np.zeros([p - len(fixedEff)])])\n",
    "\n",
    "# get theta\n",
    "Theta_i = np.zeros([n,p])\n",
    "for k in range(p):\n",
    "    if bi[k] > 0:\n",
    "        Theta_i[:,k] = st.laplace.rvs(loc = 0,scale = bi[k],size=n)\n",
    "Theta_o = np.zeros([m,p])\n",
    "for k in range(p):\n",
    "    if bo[k] > 0:\n",
    "        Theta_o[:,k] = st.laplace.rvs(loc = 0,scale = bo[k],size=m)\n",
    "\n",
    "if correlationType is 'longitudinal':\n",
    "    bo = np.zeros_like(bo)\n",
    "    Theta_o = np.zeros_like(Theta_o)\n",
    "elif correlationType is 'cluster':\n",
    "    bi = np.zeros_like(bi)\n",
    "    Theta_i = np.zeros_like(Theta_i)\n",
    "    \n",
    "allData = getData_theta(Theta_i,Theta_o,fixedEff,seed,correlationType)\n",
    "fullTrain,test = generate(allData,density=0.7,seed = seed)\n",
    "train,valid = generate(fullTrain,density=0.7,seed = seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Format data to pytorch DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "class LongitudinalData(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.X = np.array(list(data['X'].values))\n",
    "        self.y = data['y'].values\n",
    "        self.iids = data['iid'].values\n",
    "        self.oids = data['oid'].values\n",
    "        \n",
    "        indexes = np.arange(len(self.y))\n",
    "        self.mapI = defaultdict(list)\n",
    "        self.mapO = defaultdict(list)\n",
    "        for ind,(i,o) in enumerate(zip(self.iids,self.oids)):\n",
    "            self.mapI[i].append(ind)\n",
    "            self.mapO[o].append(ind)\n",
    "        self.mapI = list(self.mapI.items())\n",
    "        self.mapO = list(self.mapO.items())\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        if idx < len(self.mapI):\n",
    "            related_indexes = self.mapI[idx][1]\n",
    "            return {\n",
    "                 'X':self.X[related_indexes,:],\n",
    "                     'y':self.y[related_indexes],\n",
    "                     'target':idx,\n",
    "                     'indexes':self.oids[related_indexes],\n",
    "                     'I':True,\n",
    "                    }\n",
    "        else:\n",
    "            idx -= len(self.mapI)\n",
    "            related_indexes = np.array(self.mapO[idx][1])\n",
    "            return {\n",
    "                 'X':self.X[related_indexes,:],\n",
    "                     'y':self.y[related_indexes],\n",
    "                     'target':idx,\n",
    "                     'indexes':self.iids[related_indexes],\n",
    "                     'I':False,\n",
    "                    }\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.mapI) + len(self.mapO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = LongitudinalData(train)\n",
    "valid_ds = LongitudinalData(valid)\n",
    "full_train_ds = LongitudinalData(fullTrain)\n",
    "test_ds = LongitudinalData(test)\n",
    "train_loader = DataLoader(train_ds,batch_size=1,shuffle=True)\n",
    "valid_loader = DataLoader(valid_ds,batch_size=1,shuffle=False)\n",
    "full_train_loader = DataLoader(full_train_ds,batch_size=1,shuffle=True)\n",
    "test_loader = DataLoader(test_ds,batch_size=1,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trying tau: 2\n",
      "epoch 0 finished! loss (-): 64578.59765625\n",
      "epoch 5 finished! loss (-): 19033.84375\n",
      "training finished! loss (-): 18905.384765625\n",
      "r2 score: 0.829922916830543\n",
      "find a better solution, tau: 2, r2: 0.829922916830543, bic: 18904.67578125\n",
      "trying tau: 2.5\n",
      "epoch 0 finished! loss (-): 72699.65625\n",
      "epoch 5 finished! loss (-): 21913.10546875\n",
      "training finished! loss (-): 21875.55078125\n",
      "r2 score: 0.9425498665868475\n",
      "best tau: 2\n",
      "epoch 0 finished! loss (-): 66791.296875\n",
      "epoch 5 finished! loss (-): 18597.13671875\n",
      "training finished! loss (-): 18237.796875\n"
     ]
    }
   ],
   "source": [
    "device = 'cpu'\n",
    "dtype = torch.float\n",
    "bestLoss = 0\n",
    "bestBic = 1e10\n",
    "bestModel = None\n",
    "bestTau = 0\n",
    "for tau in [2,2.5,3,3.5,4,4.5,5]:\n",
    "    print(f'trying tau: {tau}')\n",
    "    lmlfm = LMLFM(n,m,p,device=device,alpha = tau/train['y'].var())\n",
    "    lmlfm,_ = train_lmlfm(lmlfm,train_loader,10)\n",
    "    rsq,y,y_hat  = test_lmlfm(lmlfm,valid_loader)\n",
    "    bic = lmlfm.bic(y,y_hat).item()\n",
    "    if rsq > bestLoss and bic < bestBic:\n",
    "        bestModel = lmlfm\n",
    "        bestLoss = rsq\n",
    "        bestBic = bic\n",
    "        bestTau = tau\n",
    "        print(f'find a better solution, tau: {tau}, r2: {bestLoss}, bic: {bestBic}')\n",
    "    else:\n",
    "        break\n",
    "print(f'best tau: {bestTau}')\n",
    "lmlfm = LMLFM(n,m,p,device=device,alpha = bestTau/train['y'].var())\n",
    "lmlfm,_ = train_lmlfm(lmlfm,full_train_loader,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 score: 0.880935349054059\n"
     ]
    }
   ],
   "source": [
    "rsq, y, y_hat = test_lmlfm(lmlfm,test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f.p. => 2, f.n. => 4\n"
     ]
    }
   ],
   "source": [
    "fp, fn = fp_fn(lmlfm,fixedEff)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
