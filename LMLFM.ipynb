{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_median(data, weights):\n",
    "    index = torch.argsort(data)\n",
    "    s_data = data[index]\n",
    "    s_weights = weights[index]\n",
    "    midpoint = 0.5 * s_weights.sum()\n",
    "    \n",
    "    cs_weights = torch.cumsum(s_weights,dim=0)\n",
    "    idx = torch.where(cs_weights<=midpoint)[0]\n",
    "    if len(idx) > 0:\n",
    "        idx = idx[-1]\n",
    "        if cs_weights[idx] == midpoint:\n",
    "            w_median = torch.mean(s_data[idx:idx+2])\n",
    "        else:\n",
    "            w_median = s_data[idx+1]\n",
    "        return w_median\n",
    "    else:\n",
    "        return s_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LMLFM:\n",
    "    def __init__(self,n,m,p,alpha = 1,dtype=torch.float,device='cuda'):\n",
    "        self.n = n\n",
    "        self.m = m\n",
    "        self.p = p\n",
    "        self.dtype = dtype\n",
    "        self.device = device\n",
    "        \n",
    "        self.mu_i = torch.zeros(p).type(dtype).to(device)\n",
    "        self.mu_o = torch.zeros(p).type(dtype).to(device)\n",
    "        self.Theta_i = torch.zeros([n,p]).type(dtype).to(device)\n",
    "        self.Theta_o = torch.zeros([n,p]).type(dtype).to(device)\n",
    "        self.b_i = torch.ones(p).type(dtype).to(device)\n",
    "        self.b_o = torch.ones(p).type(dtype).to(device)\n",
    "        self.b_mu_0 = self.b_b_0 = torch.ones(1).type(dtype).to(device)\n",
    "        self.alpha_0 = self.beta_0 = torch.ones(1).type(dtype).to(device)\n",
    "        self.alpha = alpha\n",
    "        \n",
    "        # constant\n",
    "        self.zeros = torch.zeros([1,self.p]).type(self.dtype).to(self.device)\n",
    "    \n",
    "    def update_alpha(self,y,y_hat):\n",
    "        residual = y - y_hat\n",
    "        self.alpha = (self.alpha_0 + len(y)/2 - 1) / (self.beta_0 + residual @ residual / 2)\n",
    "    \n",
    "    def update_b(self,I):\n",
    "        if I:\n",
    "            tmp = (self.n**2 + 4/self.b_b_0 * torch.norm(self.Theta_i-self.mu_i[None,:],p=1,dim=0)).sqrt()\n",
    "            self.b_i = 2 * self.b_b_0 * (tmp - self.n)\n",
    "        else:\n",
    "            tmp = (self.n**2 + 4/self.b_b_0 * torch.norm(self.Theta_o-self.mu_o[None,:],p=1,dim=0)).sqrt()\n",
    "            self.b_o = 2 * self.b_b_0 * (tmp - self.n)\n",
    "    \n",
    "    def update_mu(self,I):\n",
    "        if I:\n",
    "            dta = torch.cat([self.Theta_i,self.zeros],dim=0)\n",
    "            for k in range(self.p):\n",
    "                weights = torch.ones_like(dta[:,k]) * self.b_i[k]\n",
    "                weights[-1] = self.b_mu_0\n",
    "                self.mu_i[k] = weighted_median(dta[:,k],weights)\n",
    "        else:\n",
    "            dta = torch.cat([self.Theta_o,self.zeros],dim=0)\n",
    "            for k in range(self.p):\n",
    "                weights = torch.ones_like(dta[:,k]) * self.b_o[k]\n",
    "                weights[-1] = self.b_mu_0\n",
    "                self.mu_o[k] = weighted_median(dta[:,k],weights)\n",
    "    \n",
    "    def update_theta(self,X,y,target,indexes,I):\n",
    "        if I:\n",
    "            theta = self.Theta_i[target].reshape(-1)\n",
    "            g = torch.zeros_like(y)\n",
    "            for i in range(len(g)):\n",
    "                g[i] = X[i] @ self.Theta_o[indexes[i]]\n",
    "#             g = torch.diag(X @ self.Theta_o[indexes].t()) # ni\n",
    "            h = X + self.Theta_o[indexes] # ni * p\n",
    "            y_hat = h @ theta + g\n",
    "            col = y - y_hat\n",
    "        \n",
    "            newv = torch.zeros_like(theta)\n",
    "            for k in torch.randperm(self.p):\n",
    "                if self.b_i[k] == 0:\n",
    "                    newv[k] = self.mu_i[k]\n",
    "                else:\n",
    "                    bottom = h[:,k] @ h[:,k]\n",
    "                    col += h[:,k] * theta[k]\n",
    "                    C = h[:,k] @ col\n",
    "                    Ccheck = C - bottom * self.mu_i[k]\n",
    "                    sub = 1 / (self.alpha * self.b_i[k])\n",
    "                    if Ccheck >= -sub and Ccheck <= sub:\n",
    "                        newv[k] = self.mu_i[k]\n",
    "                    elif Ccheck > sub:\n",
    "                        newv[k] = (C - sub) / bottom\n",
    "                    else:\n",
    "                        newv[k] = (C + sub) / bottom\n",
    "                    col -= h[:, k] * newv[k]\n",
    "            self.Theta_i[target] = newv\n",
    "            return h @ newv + g\n",
    "        else:\n",
    "            theta = self.Theta_o[target].reshape(-1)\n",
    "            g = torch.zeros_like(y)\n",
    "            for i in range(len(g)):\n",
    "                g[i] = X[i] @ self.Theta_i[indexes[i]]\n",
    "#             g = torch.diag(X @ self.Theta_i[indexes].t()) # ni\n",
    "            h = X + self.Theta_i[indexes] # ni * p\n",
    "            y_hat = h @ theta + g\n",
    "            col = y - y_hat\n",
    "            \n",
    "            newv = torch.zeros_like(theta)\n",
    "            for k in torch.randperm(self.p):\n",
    "                if self.b_o[k] == 0:\n",
    "                    newv[k] = self.mu_o[k]\n",
    "                else:\n",
    "                    bottom = h[:,k] @ h[:,k]\n",
    "                    col += h[:,k] * theta[k]\n",
    "                    C = h[:,k] @ col\n",
    "                    Ccheck = C - bottom * self.mu_o[k]\n",
    "                    sub = 1 / (self.alpha * self.b_o[k])\n",
    "                    if Ccheck >= -sub and Ccheck <= sub:\n",
    "                        newv[k] = self.mu_o[k]\n",
    "                    elif Ccheck > sub:\n",
    "                        newv[k] = (C - sub) / bottom\n",
    "                    else:\n",
    "                        newv[k] = (C + sub) / bottom\n",
    "                    col -= h[:, k] * newv[k]\n",
    "            self.Theta_o[target] = newv\n",
    "            return h @ newv + g\n",
    "        \n",
    "    def predict(self,X, target, indexes, I):\n",
    "        if I:\n",
    "            if target < self.n:\n",
    "                theta = self.Theta_i[target].reshape(-1)\n",
    "            else:\n",
    "                theta = self.mu_i\n",
    "            factors = torch.zeros_like(self.Theta_o[:len(indexes)])\n",
    "            for i,each in enumerate(indexes):\n",
    "                factors[i] = self.Theta_o[each] if each < self.m else self.mu_o\n",
    "            g = torch.diag(X @ factors.t()) # ni\n",
    "            h = X + factors # ni * p\n",
    "            y_hat = h @ theta + g\n",
    "        else:\n",
    "            if target < self.m:\n",
    "                theta = self.Theta_o[target].reshape(-1)\n",
    "            else:\n",
    "                theta = self.mu_o\n",
    "            factors = torch.zeros_like(self.Theta_i[:len(indexes)])\n",
    "            for i,each in enumerate(indexes):\n",
    "                factors[i] = self.Theta_i[each] if each < self.n else self.mu_i\n",
    "            g = torch.diag(X @ factors.t()) # ni\n",
    "            h = X + factors # ni * p\n",
    "            y_hat = h @ theta + g\n",
    "        return y_hat\n",
    "    \n",
    "    def fixedEffect(self,rounding=2):\n",
    "        mask = (self.b_i + self.b_o) == 0\n",
    "        effects = self.mu_i + self.mu_o\n",
    "        return np.round(effects.cpu().numpy(),rounding),mask\n",
    "    \n",
    "    def mapLoss(self, y, y_hat,eps=1e-6): # the larger the better, ascent property and convergence guarantee\n",
    "        residual = y - y_hat\n",
    "        sumloss = residual @ residual\n",
    "        lly = 0.5 * len(y) * (self.alpha/2.51).log() - 0.5 * self.alpha * sumloss\n",
    "#         pos = self.b_i > 0\n",
    "#         llTheta_i = -(2*self.b_i[pos]).log().sum() * self.n - ((self.Theta_i[:,pos] - self.mu_i[None,pos]).abs() / self.b_i[None,pos]).sum()\n",
    "        llTheta_i = -(2*self.b_i + eps).log().sum() * self.n - ((self.Theta_i - self.mu_i[None,:]).abs() / (self.b_i[None,:] + eps)).sum()\n",
    "#         pos = self.b_o > 0\n",
    "#         llTheta_o = -(2*self.b_o[pos]).log().sum() * self.m - ((self.Theta_o[:,pos] - self.mu_o[None,pos]).abs() / self.b_o[None,pos]).sum()\n",
    "        llTheta_o = -(2*self.b_o + eps).log().sum() * self.m - ((self.Theta_o - self.mu_o[None,:]).abs() / (self.b_o[None,:] + eps)).sum()\n",
    "        llmu_i = -self.mu_i.abs().sum() / self.b_mu_0\n",
    "        llmu_o = -self.mu_o.abs().sum() / self.b_mu_0\n",
    "        llb_i = -self.b_i.abs().sum() / self.b_b_0\n",
    "        llb_o = -self.b_o.abs().sum() / self.b_b_0\n",
    "        return (lly + llTheta_i + llTheta_o + llmu_i + llmu_o + llb_i + llb_o) / len(y)\n",
    "    \n",
    "    def bic(self, y, y_hat): # the smaller the better\n",
    "        residual = y - y_hat\n",
    "        sumloss = residual @ residual\n",
    "        lly = 0.5 * len(y) * (self.alpha/2.51).log() - 0.5 * self.alpha * sumloss\n",
    "        gt_zero = (self.Theta_i.abs()>0).sum() + (self.Theta_o.abs()>0).sum() + (self.mu_i.abs()>0).sum() \\\n",
    "        + (self.mu_o.abs()>0).sum() + (self.b_i>0).sum() + (self.b_o>0).sum()\n",
    "        return -2 * lly + gt_zero * np.log(len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset and dataloader\n",
    "class LongitudinalData(Dataset):\n",
    "    def __init__(self, X, y, iids, oids):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.iids = iids\n",
    "        self.oids = oids\n",
    "        \n",
    "        indexes = np.arange(len(y))\n",
    "        self.mapI = defaultdict(list)\n",
    "        self.mapO = defaultdict(list)\n",
    "        for ind,(i,o) in enumerate(zip(iids,oids)):\n",
    "            self.mapI[i].append(ind)\n",
    "            self.mapO[o].append(ind)\n",
    "\n",
    "        self.n = len(self.mapI)\n",
    "        self.m = len(self.mapO)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        if idx < self.n:\n",
    "            related_indexes = np.array(self.mapI[idx])\n",
    "            return {\n",
    "                 'X':self.X[related_indexes,:],\n",
    "                     'y':self.y[related_indexes],\n",
    "                     'target':idx,\n",
    "                     'indexes':self.oids[related_indexes],\n",
    "                     'I':True,\n",
    "                    }\n",
    "        else:\n",
    "            idx -= self.n\n",
    "            related_indexes = np.array(self.mapO[idx])\n",
    "            return {\n",
    "                 'X':self.X[related_indexes,:],\n",
    "                     'y':self.y[related_indexes],\n",
    "                     'target':idx,\n",
    "                     'indexes':self.iids[related_indexes],\n",
    "                     'I':False,\n",
    "                    }\n",
    "            \n",
    "    def __len__(self):\n",
    "        return self.n + self.m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lmlfm(lmlfm,train_loader,epochs):\n",
    "    for i in range(epochs):\n",
    "        y_cat = None\n",
    "        y_hat_cat = None\n",
    "        for cur,each in enumerate(train_loader):\n",
    "            X = each['X'][0].type(dtype).to(device)\n",
    "            y = each['y'][0].reshape(-1).type(dtype).to(device)\n",
    "            target = each['target']\n",
    "            indexes = each['indexes'].reshape(-1).type(torch.long).to(device)\n",
    "            I = each['I']\n",
    "            y_hat = lmlfm.update_theta(X,y,target,indexes,I)\n",
    "            \n",
    "            if cur == 0:\n",
    "                y_cat = y\n",
    "                y_hat_cat = y_hat\n",
    "            else:\n",
    "                y_cat = torch.cat([y_cat,y],dim=0)\n",
    "                y_hat_cat = torch.cat([y_hat_cat,y_hat],dim=0)\n",
    "        lmlfm.update_alpha(y_cat,y_hat_cat)\n",
    "        lmlfm.update_mu(True)\n",
    "        lmlfm.update_mu(False)\n",
    "        lmlfm.update_b(True)\n",
    "        lmlfm.update_b(False)\n",
    "#         loss = lmlfm.mapLoss(y_cat, y_hat_cat)\n",
    "#         print(f'epoch {i} finished! loss (+): {loss.item()}')\n",
    "        if i % 5 == 0:\n",
    "            loss = lmlfm.bic(y_cat,y_hat_cat)\n",
    "            print(f'epoch {i} finished! loss (-): {loss.item()}')\n",
    "            \n",
    "    loss = lmlfm.bic(y_cat,y_hat_cat)\n",
    "    print(f'training finished! loss (-): {loss.item()}')\n",
    "    return lmlfm,loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "def test_lmlfm(lmlfm,test):\n",
    "    y_cat = None\n",
    "    y_hat_cat = None\n",
    "    for cur,each in enumerate(train_loader):\n",
    "        X = each['X'][0].type(dtype).to(device)\n",
    "        y = each['y'][0].reshape(-1).type(dtype).to(device)\n",
    "        target = each['target']\n",
    "        indexes = each['indexes'].reshape(-1).type(torch.long).to(device)\n",
    "        I = each['I']\n",
    "        y_hat = lmlfm.predict(X,target,indexes,I)\n",
    "\n",
    "        if cur == 0:\n",
    "            y_cat = y\n",
    "            y_hat_cat = y_hat\n",
    "        else:\n",
    "            y_cat = torch.cat([y_cat,y],dim=0)\n",
    "            y_hat_cat = torch.cat([y_hat_cat,y_hat],dim=0)\n",
    "    r2score = r2_score(y_cat.cpu().numpy(),y_hat_cat.cpu().numpy())\n",
    "#     print(f'r2 score: {r2score}')\n",
    "    return r2score,y_cat,y_hat_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fp_fn(lmlfm,groundtruth):\n",
    "    _,mask = lmlfm.fixedEffect()\n",
    "    mask = ~mask\n",
    "    gt = groundtruth != 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "    for h,y in zip(mask,gt):\n",
    "        if h and not y:\n",
    "            fp += 1\n",
    "        elif not h and y:\n",
    "            fn += 1\n",
    "    print(f'f.p. => {fp}, f.n. => {fn}')\n",
    "    return fp,fn"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
